finetune:
  batch_size: 64
  dataset: but_ppg
  epochs: 20
  freeze_encoder: false
  learning_rate: 1.0e-05
optimization:
  cache_size: 1000
  compile_model: true
  mixed_precision: true
  use_cache: true
pretrain:
  batch_size: 128
  dataset: vitaldb
  early_stopping_patience: 15
  epochs: 50
  save_freq: 10
ssl:
  augmentations_ppg:
    channel_permute: 0.0
    cutout: 0.7
    gaussian_noise: 0.5
    magnitude_warp: 0.5
    time_warp: 0.3
  lambda_koleo: 0.1
  momentum_rate: 0.996
  temperature: 0.04
training:
  batch_size: 256
  gradient_accumulation_steps: 4
  learning_rate: 0.001
  num_workers: 8
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 2
